{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import libpysal\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import os.path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_chunk = pd.read_parquet('../../urbangrammar_samba/spatial_signatures/cross-chunk_indices.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(chunk_id):\n",
    "    s = time()\n",
    "    cells = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk_id}.pq\")\n",
    "    cells['keep'] = True\n",
    "    # add neighbouring cells from other chunks\n",
    "    cross_chunk_cells = []\n",
    "\n",
    "    for chunk, inds in cross_chunk.loc[chunk_id].indices.iteritems():\n",
    "        add_cells = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk}.pq\").iloc[inds]\n",
    "        add_cells['keep'] = False\n",
    "        cross_chunk_cells.append(add_cells)\n",
    "\n",
    "    df = cells.append(pd.concat(cross_chunk_cells, ignore_index=True), ignore_index=True)\n",
    "\n",
    "    # read W\n",
    "    w = libpysal.weights.WSP(scipy.sparse.load_npz(f\"../../urbangrammar_samba/spatial_signatures/weights/w3_{chunk_id}.npz\")).to_W()\n",
    "\n",
    "    characters = ['ltbIBD', 'stbCeA']\n",
    "    \n",
    "    convolutions = {}\n",
    "    for c in characters:\n",
    "        convolutions[c] = []\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        neighbours = [i]\n",
    "        neighbours += w.neighbors[i]\n",
    "\n",
    "        vicinity = df.iloc[neighbours]\n",
    "\n",
    "        for c in characters:\n",
    "            convolutions[c].append(np.nanpercentile(vicinity[c], [25, 50, 75], interpolation='midpoint'))\n",
    "    \n",
    "    conv = pd.DataFrame(convolutions)\n",
    "    exploded = pd.concat([pd.DataFrame(conv[c].to_list(), columns=[c + '_q1', c + '_q2',c + '_q3']) for c in characters], axis=1)\n",
    "    \n",
    "    existing = pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/convolutions/conv_{chunk_id}.pq\")\n",
    "    \n",
    "    existing[exploded.columns] = exploded[df.keep]\n",
    "    existing.to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/convolutions/conv_{chunk_id}.pq\")\n",
    "        \n",
    "    return f\"Chunk {chunk_id} processed sucessfully in {time() - s} seconds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45725</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>84.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45725' processes=8 threads=8, memory=84.28 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers = 8\n",
    "client = Client(LocalCluster(n_workers=workers, threads_per_worker=1))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed sucessfully in 208.44732093811035 seconds.\n",
      "Chunk 3 processed sucessfully in 248.29846453666687 seconds.\n",
      "Chunk 2 processed sucessfully in 276.4308907985687 seconds.\n",
      "Chunk 1 processed sucessfully in 289.92260479927063 seconds.\n",
      "Chunk 7 processed sucessfully in 324.9429392814636 seconds.\n",
      "Chunk 4 processed sucessfully in 358.24270963668823 seconds.\n",
      "Chunk 5 processed sucessfully in 431.5343999862671 seconds.\n",
      "Chunk 9 processed sucessfully in 259.7171881198883 seconds.\n",
      "Chunk 8 processed sucessfully in 302.14715337753296 seconds.\n",
      "Chunk 11 processed sucessfully in 226.80128169059753 seconds.\n",
      "Chunk 10 processed sucessfully in 248.843092918396 seconds.\n",
      "Chunk 6 processed sucessfully in 555.3480136394501 seconds.\n",
      "Chunk 13 processed sucessfully in 289.82896614074707 seconds.\n",
      "Chunk 12 processed sucessfully in 381.17248272895813 seconds.\n",
      "Chunk 14 processed sucessfully in 297.7357301712036 seconds.\n",
      "Chunk 15 processed sucessfully in 234.40446066856384 seconds.\n",
      "Chunk 18 processed sucessfully in 226.0597538948059 seconds.\n",
      "Chunk 16 processed sucessfully in 241.86770915985107 seconds.\n",
      "Chunk 17 processed sucessfully in 240.73298048973083 seconds.\n",
      "Chunk 19 processed sucessfully in 277.0079092979431 seconds.\n",
      "Chunk 20 processed sucessfully in 254.28818893432617 seconds.\n",
      "Chunk 21 processed sucessfully in 233.51667022705078 seconds.\n",
      "Chunk 22 processed sucessfully in 234.61178827285767 seconds.\n",
      "Chunk 23 processed sucessfully in 231.6014678478241 seconds.\n",
      "Chunk 25 processed sucessfully in 239.64363813400269 seconds.\n",
      "Chunk 26 processed sucessfully in 316.9290111064911 seconds.\n",
      "Chunk 24 processed sucessfully in 328.9268362522125 seconds.\n",
      "Chunk 28 processed sucessfully in 208.89338183403015 seconds.\n",
      "Chunk 27 processed sucessfully in 283.57721877098083 seconds.\n",
      "Chunk 29 processed sucessfully in 246.2465181350708 seconds.\n",
      "Chunk 31 processed sucessfully in 238.88144540786743 seconds.\n",
      "Chunk 30 processed sucessfully in 287.30551195144653 seconds.\n",
      "Chunk 34 processed sucessfully in 231.13897967338562 seconds.\n",
      "Chunk 36 processed sucessfully in 205.89630436897278 seconds.\n",
      "Chunk 33 processed sucessfully in 257.44033575057983 seconds.\n",
      "Chunk 32 processed sucessfully in 390.7083203792572 seconds.\n",
      "Chunk 35 processed sucessfully in 276.322890996933 seconds.\n",
      "Chunk 37 processed sucessfully in 291.2216320037842 seconds.\n",
      "Chunk 39 processed sucessfully in 249.75490140914917 seconds.\n",
      "Chunk 41 processed sucessfully in 275.480477809906 seconds.\n",
      "Chunk 42 processed sucessfully in 288.0375065803528 seconds.\n",
      "Chunk 38 processed sucessfully in 412.69333243370056 seconds.\n",
      "Chunk 44 processed sucessfully in 239.7059998512268 seconds.\n",
      "Chunk 43 processed sucessfully in 251.72225761413574 seconds.\n",
      "Chunk 45 processed sucessfully in 281.72161960601807 seconds.\n",
      "Chunk 40 processed sucessfully in 456.998330116272 seconds.\n",
      "Chunk 46 processed sucessfully in 284.4023332595825 seconds.\n",
      "Chunk 47 processed sucessfully in 226.14084458351135 seconds.\n",
      "Chunk 51 processed sucessfully in 255.93345093727112 seconds.\n",
      "Chunk 48 processed sucessfully in 279.1467218399048 seconds.\n",
      "Chunk 49 processed sucessfully in 271.4305000305176 seconds.\n",
      "Chunk 50 processed sucessfully in 309.0113203525543 seconds.\n",
      "Chunk 52 processed sucessfully in 212.99244213104248 seconds.\n",
      "Chunk 55 processed sucessfully in 217.3812701702118 seconds.\n",
      "Chunk 53 processed sucessfully in 278.72648334503174 seconds.\n",
      "Chunk 54 processed sucessfully in 273.38547825813293 seconds.\n",
      "Chunk 58 processed sucessfully in 244.9360547065735 seconds.\n",
      "Chunk 57 processed sucessfully in 245.5131015777588 seconds.\n",
      "Chunk 56 processed sucessfully in 282.28073382377625 seconds.\n",
      "Chunk 59 processed sucessfully in 270.7292478084564 seconds.\n",
      "Chunk 60 processed sucessfully in 246.27286434173584 seconds.\n",
      "Chunk 63 processed sucessfully in 239.5272033214569 seconds.\n",
      "Chunk 62 processed sucessfully in 277.8344757556915 seconds.\n",
      "Chunk 65 processed sucessfully in 315.8760197162628 seconds.\n",
      "Chunk 66 processed sucessfully in 319.44311475753784 seconds.\n",
      "Chunk 61 processed sucessfully in 457.18267798423767 seconds.\n",
      "Chunk 68 processed sucessfully in 300.26176714897156 seconds.\n",
      "Chunk 64 processed sucessfully in 417.27109837532043 seconds.\n",
      "Chunk 69 processed sucessfully in 293.73982858657837 seconds.\n",
      "Chunk 70 processed sucessfully in 284.93872714042664 seconds.\n",
      "Chunk 67 processed sucessfully in 412.0450875759125 seconds.\n",
      "Chunk 71 processed sucessfully in 291.8425726890564 seconds.\n",
      "Chunk 72 processed sucessfully in 268.4682309627533 seconds.\n",
      "Chunk 74 processed sucessfully in 262.65558648109436 seconds.\n",
      "Chunk 73 processed sucessfully in 324.4285087585449 seconds.\n",
      "Chunk 78 processed sucessfully in 235.6069679260254 seconds.\n",
      "Chunk 77 processed sucessfully in 278.1140704154968 seconds.\n",
      "Chunk 75 processed sucessfully in 348.66928124427795 seconds.\n",
      "Chunk 76 processed sucessfully in 328.92932081222534 seconds.\n",
      "Chunk 81 processed sucessfully in 196.19851303100586 seconds.\n",
      "Chunk 79 processed sucessfully in 245.159606218338 seconds.\n",
      "Chunk 80 processed sucessfully in 315.09837794303894 seconds.\n",
      "Chunk 84 processed sucessfully in 219.02275967597961 seconds.\n",
      "Chunk 82 processed sucessfully in 285.8399701118469 seconds.\n",
      "Chunk 83 processed sucessfully in 281.3869957923889 seconds.\n",
      "Chunk 86 processed sucessfully in 306.3119013309479 seconds.\n",
      "Chunk 85 processed sucessfully in 323.9976794719696 seconds.\n",
      "Chunk 87 processed sucessfully in 276.98210740089417 seconds.\n",
      "Chunk 88 processed sucessfully in 295.8213140964508 seconds.\n",
      "Chunk 90 processed sucessfully in 234.8686761856079 seconds.\n",
      "Chunk 91 processed sucessfully in 259.32629346847534 seconds.\n",
      "Chunk 93 processed sucessfully in 229.32500004768372 seconds.\n",
      "Chunk 89 processed sucessfully in 410.32233715057373 seconds.\n",
      "Chunk 94 processed sucessfully in 254.06217098236084 seconds.\n",
      "Chunk 92 processed sucessfully in 380.2310461997986 seconds.\n",
      "Chunk 96 processed sucessfully in 225.72124695777893 seconds.\n",
      "Chunk 95 processed sucessfully in 272.0251166820526 seconds.\n",
      "Chunk 97 processed sucessfully in 241.61350107192993 seconds.\n",
      "Chunk 99 processed sucessfully in 278.82684326171875 seconds.\n",
      "Chunk 98 processed sucessfully in 376.5779938697815 seconds.\n",
      "Chunk 100 processed sucessfully in 269.484717130661 seconds.\n",
      "Chunk 102 processed sucessfully in 275.24881291389465 seconds.\n",
      "Chunk 101 processed sucessfully in 466.2110798358917 seconds.\n",
      "CPU times: user 7min 49s, sys: 55.1 s, total: 8min 44s\n",
      "Wall time: 1h 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = iter(range(103))\n",
    "futures = [client.submit(convolute, next(inputs)) for i in range(workers)]\n",
    "ac = as_completed(futures)\n",
    "for finished_future in ac:\n",
    "    # submit new future \n",
    "    try:\n",
    "        new_future = client.submit(convolute, next(inputs))\n",
    "        ac.add(new_future)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    print(finished_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/convolutions/conv_0.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 has 0 rows with at least one NaN.\n",
      "Chunk 1 has 0 rows with at least one NaN.\n",
      "Chunk 2 has 0 rows with at least one NaN.\n",
      "Chunk 3 has 0 rows with at least one NaN.\n",
      "Chunk 4 has 0 rows with at least one NaN.\n",
      "Chunk 5 has 167 rows with at least one NaN.\n",
      "Chunk 6 has 0 rows with at least one NaN.\n",
      "Chunk 7 has 0 rows with at least one NaN.\n",
      "Chunk 8 has 0 rows with at least one NaN.\n",
      "Chunk 9 has 0 rows with at least one NaN.\n",
      "Chunk 10 has 3 rows with at least one NaN.\n",
      "Chunk 11 has 0 rows with at least one NaN.\n",
      "Chunk 12 has 0 rows with at least one NaN.\n",
      "Chunk 13 has 2 rows with at least one NaN.\n",
      "Chunk 14 has 3 rows with at least one NaN.\n",
      "Chunk 15 has 0 rows with at least one NaN.\n",
      "Chunk 16 has 0 rows with at least one NaN.\n",
      "Chunk 17 has 0 rows with at least one NaN.\n",
      "Chunk 18 has 0 rows with at least one NaN.\n",
      "Chunk 19 has 0 rows with at least one NaN.\n",
      "Chunk 20 has 3 rows with at least one NaN.\n",
      "Chunk 21 has 0 rows with at least one NaN.\n",
      "Chunk 22 has 0 rows with at least one NaN.\n",
      "Chunk 23 has 0 rows with at least one NaN.\n",
      "Chunk 24 has 0 rows with at least one NaN.\n",
      "Chunk 25 has 0 rows with at least one NaN.\n",
      "Chunk 26 has 1 rows with at least one NaN.\n",
      "Chunk 27 has 0 rows with at least one NaN.\n",
      "Chunk 28 has 0 rows with at least one NaN.\n",
      "Chunk 29 has 19 rows with at least one NaN.\n",
      "Chunk 30 has 0 rows with at least one NaN.\n",
      "Chunk 31 has 13 rows with at least one NaN.\n",
      "Chunk 32 has 75 rows with at least one NaN.\n",
      "Chunk 33 has 48 rows with at least one NaN.\n",
      "Chunk 34 has 18 rows with at least one NaN.\n",
      "Chunk 35 has 0 rows with at least one NaN.\n",
      "Chunk 36 has 8 rows with at least one NaN.\n",
      "Chunk 37 has 11 rows with at least one NaN.\n",
      "Chunk 38 has 21 rows with at least one NaN.\n",
      "Chunk 39 has 0 rows with at least one NaN.\n",
      "Chunk 40 has 0 rows with at least one NaN.\n",
      "Chunk 41 has 0 rows with at least one NaN.\n",
      "Chunk 42 has 22 rows with at least one NaN.\n",
      "Chunk 43 has 0 rows with at least one NaN.\n",
      "Chunk 44 has 0 rows with at least one NaN.\n",
      "Chunk 45 has 0 rows with at least one NaN.\n",
      "Chunk 46 has 0 rows with at least one NaN.\n",
      "Chunk 47 has 20 rows with at least one NaN.\n",
      "Chunk 48 has 29 rows with at least one NaN.\n",
      "Chunk 49 has 6 rows with at least one NaN.\n",
      "Chunk 50 has 0 rows with at least one NaN.\n",
      "Chunk 51 has 1 rows with at least one NaN.\n",
      "Chunk 52 has 0 rows with at least one NaN.\n",
      "Chunk 53 has 0 rows with at least one NaN.\n",
      "Chunk 54 has 0 rows with at least one NaN.\n",
      "Chunk 55 has 0 rows with at least one NaN.\n",
      "Chunk 56 has 3 rows with at least one NaN.\n",
      "Chunk 57 has 10 rows with at least one NaN.\n",
      "Chunk 58 has 66 rows with at least one NaN.\n",
      "Chunk 59 has 1 rows with at least one NaN.\n",
      "Chunk 60 has 0 rows with at least one NaN.\n",
      "Chunk 61 has 0 rows with at least one NaN.\n",
      "Chunk 62 has 1 rows with at least one NaN.\n",
      "Chunk 63 has 1 rows with at least one NaN.\n",
      "Chunk 64 has 48 rows with at least one NaN.\n",
      "Chunk 65 has 4 rows with at least one NaN.\n",
      "Chunk 66 has 12 rows with at least one NaN.\n",
      "Chunk 67 has 0 rows with at least one NaN.\n",
      "Chunk 68 has 2 rows with at least one NaN.\n",
      "Chunk 69 has 15 rows with at least one NaN.\n",
      "Chunk 70 has 2 rows with at least one NaN.\n",
      "Chunk 71 has 2 rows with at least one NaN.\n",
      "Chunk 72 has 0 rows with at least one NaN.\n",
      "Chunk 73 has 21 rows with at least one NaN.\n",
      "Chunk 74 has 0 rows with at least one NaN.\n",
      "Chunk 75 has 0 rows with at least one NaN.\n",
      "Chunk 76 has 3 rows with at least one NaN.\n",
      "Chunk 77 has 4 rows with at least one NaN.\n",
      "Chunk 78 has 9 rows with at least one NaN.\n",
      "Chunk 79 has 0 rows with at least one NaN.\n",
      "Chunk 80 has 0 rows with at least one NaN.\n",
      "Chunk 81 has 7 rows with at least one NaN.\n",
      "Chunk 82 has 23 rows with at least one NaN.\n",
      "Chunk 83 has 14 rows with at least one NaN.\n",
      "Chunk 84 has 2 rows with at least one NaN.\n",
      "Chunk 85 has 37 rows with at least one NaN.\n",
      "Chunk 86 has 0 rows with at least one NaN.\n",
      "Chunk 87 has 681 rows with at least one NaN.\n",
      "Chunk 88 has 0 rows with at least one NaN.\n",
      "Chunk 89 has 66 rows with at least one NaN.\n",
      "Chunk 90 has 0 rows with at least one NaN.\n",
      "Chunk 91 has 0 rows with at least one NaN.\n",
      "Chunk 92 has 0 rows with at least one NaN.\n",
      "Chunk 93 has 0 rows with at least one NaN.\n",
      "Chunk 94 has 0 rows with at least one NaN.\n",
      "Chunk 95 has 0 rows with at least one NaN.\n",
      "Chunk 96 has 0 rows with at least one NaN.\n",
      "Chunk 97 has 277 rows with at least one NaN.\n",
      "Chunk 98 has 4 rows with at least one NaN.\n",
      "Chunk 99 has 30 rows with at least one NaN.\n",
      "Chunk 100 has 4 rows with at least one NaN.\n",
      "Chunk 101 has 0 rows with at least one NaN.\n",
      "Chunk 102 has 0 rows with at least one NaN.\n"
     ]
    }
   ],
   "source": [
    "for chunk_id in range(103):\n",
    "    cells = pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/convolutions/conv_{chunk_id}.pq\")\n",
    "    print(f\"Chunk {chunk_id} has {cells.isna().any(axis=1).sum()} rows with at least one NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
