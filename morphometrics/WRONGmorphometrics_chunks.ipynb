{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyarrow/compat.py:25: FutureWarning: pyarrow.compat has been deprecated and will be removed in a future release\n",
      "  \"future release\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask_geopandas as dask_geopandas\n",
    "import dask\n",
    "from dask.distributed import as_completed\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "import geopandas\n",
    "import pygeos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import momepy\n",
    "\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from libpysal.weights import Queen\n",
    "\n",
    "from momepy_utils import street_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43981</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>84.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43981' processes=2 threads=2, memory=84.28 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers = 2\n",
    "client = Client(LocalCluster(n_workers=workers, threads_per_worker=1))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_chunk = pd.read_parquet('../../urbangrammar_samba/spatial_signatures/cross-chunk_indices.pq')\n",
    "# chunks = geopandas.read_parquet('../../urbangrammar_samba/spatial_signatures/local_auth_chunks.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.environ.get('DB_USER')\n",
    "pwd = os.environ.get('DB_PWD')\n",
    "host = os.environ.get('DB_HOST')\n",
    "port = os.environ.get('DB_PORT')\n",
    "\n",
    "db_connection_url = f\"postgres+psycopg2://{user}:{pwd}@{host}:{port}/built_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(chunk_id):\n",
    "    blg = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/buildings/blg_{chunk_id}.pq\")\n",
    "    tess = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/tessellation/tess_{chunk_id}.pq\")\n",
    "    orig_ids = tess.uID.copy()\n",
    "    \n",
    "    # expand across the chunk boundary\n",
    "    additional_tess = []\n",
    "    addtional_blg = []\n",
    "    add_tess_data = []\n",
    "    for chunk, inds in cross_chunk.loc[chunk_id].indices.iteritems():\n",
    "        add_tess = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/tessellation/tess_{chunk}.pq\").iloc[inds]\n",
    "        additional_tess.append(add_tess)\n",
    "        add_blg = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/buildings/blg_{chunk}.pq\")\n",
    "        addtional_blg.append(add_blg[add_blg.uID.isin(add_tess.uID)])\n",
    "        tess_data = pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk}.pq\")\n",
    "        add_tess_data.append(tess_data[tess_data.uID.isin(add_tess.uID)])\n",
    "    \n",
    "    add_tess_data.append(pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk_id}.pq\"))\n",
    "    additional_tess.append(tess)\n",
    "    tess = pd.concat(additional_tess)\n",
    "    addtional_blg.append(blg)\n",
    "    blg = pd.concat(addtional_blg)\n",
    "    \n",
    "    blg = blg.rename_geometry('buildings')\n",
    "    tess = tess.rename_geometry('tessellation')\n",
    "\n",
    "    df = tess.merge(blg, on='uID', how='left')\n",
    "    df = df.merge(pd.concat(add_tess_data).drop(columns='enclosureID'), on='uID', how='left')\n",
    "    \n",
    "    # make 3d geometry 2d\n",
    "    coords = pygeos.get_coordinates(df.tessellation.values.data)\n",
    "    counts = pygeos.get_num_coordinates(df.tessellation.values.data)\n",
    "    df['tessellation'] = geopandas.GeoSeries([pygeos.polygons(c) for c in np.split(coords, np.cumsum(counts)[:-1])], crs=df.tessellation.crs)\n",
    "\n",
    "    w = Queen.from_dataframe(df, geom_col='tessellation')\n",
    "\n",
    "    df['ix'] = range(len(df))\n",
    "\n",
    "\n",
    "    def alignment(x, orientation):\n",
    "        orientations = df[orientation].iloc[w.neighbors[x]]\n",
    "        return abs(orientations - df[orientation].iloc[x]).mean()\n",
    "\n",
    "\n",
    "    df['mtbAli'] = df.ix.apply(alignment, args=('stbOri',))\n",
    "\n",
    "\n",
    "    def neighbor_distance(x):\n",
    "        geom = df.buildings.iloc[x]\n",
    "        if geom is None:\n",
    "            return np.nan\n",
    "        return df.buildings.iloc[w.neighbors[x]].distance(df.buildings.iloc[x]).mean()\n",
    "\n",
    "\n",
    "    df['mtbNDi'] = df.ix.apply(neighbor_distance)\n",
    "\n",
    "    df['mtcWNe'] = df.ix.apply(lambda x: w.cardinalities[x]) / df.tessellation.length\n",
    "\n",
    "\n",
    "    def area_covered(x, area):\n",
    "        neighbours = [x]\n",
    "        neighbours += w.neighbors[x]\n",
    "\n",
    "        return df[area].iloc[neighbours].sum()\n",
    "\n",
    "\n",
    "    df['mdcAre'] = df.ix.apply(area_covered, args=('sdcAre',))\n",
    "\n",
    "    w3 = momepy.sw_high(k=3, weights=w)\n",
    "\n",
    "    # define adjacency list from lipysal\n",
    "#     adj_list = w.to_adjlist(remove_symmetric=True)\n",
    "#     adj_list[\"distance\"] = (\n",
    "#         df.buildings.iloc[adj_list.focal]\n",
    "#         .reset_index(drop=True)\n",
    "#         .distance(df.buildings.iloc[adj_list.neighbor].reset_index(drop=True))\n",
    "#     )\n",
    "#     adj_list = adj_list.set_index(['focal', 'neighbor'])\n",
    "\n",
    "\n",
    "#     def mean_interbuilding_distance(x):\n",
    "#         neighbours = [x]\n",
    "#         neighbours += w3.neighbors[x]\n",
    "#         return adj_list.distance.loc[neighbours, neighbours].mean()\n",
    "\n",
    "\n",
    "#     df['ltbIBD'] = df.ix.apply(mean_interbuilding_distance)\n",
    "\n",
    "\n",
    "    def weighted_reached_enclosures(x, area, enclosure_id):\n",
    "        neighbours = [x]\n",
    "        neighbours += w3.neighbors[x]\n",
    "\n",
    "        vicinity = df[[area, enclosure_id]].iloc[neighbours]\n",
    "\n",
    "        return vicinity[enclosure_id].unique().shape[0] / vicinity[area].sum()\n",
    "\n",
    "    df['ltcWRE'] = df.ix.apply(weighted_reached_enclosures, args=('sdcAre', 'enclosureID'))\n",
    "    \n",
    "    df[df.uID.isin(orig_ids)].drop(columns=['buildings', 'tessellation']).to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk_id}.pq\")\n",
    "    \n",
    "    \n",
    "#     chunk_area = chunks.geometry.iloc[chunk_id].buffer(5000)\n",
    "#     engine = create_engine(db_connection_url)\n",
    "#     sql = f\"SELECT * FROM openroads_200803_topological WHERE ST_Intersects(geometry, ST_GeomFromText('{chunk_area.wkt}',27700))\"\n",
    "#     streets = geopandas.read_postgis(sql, engine, geom_col='geometry')\n",
    "    \n",
    "#     sp = street_profile(streets, blg)\n",
    "#     streets['sdsSPW'] = sp[0]\n",
    "#     streets['sdsSWD'] = sp[1]\n",
    "#     streets['sdsSPO'] = sp[2]\n",
    "    \n",
    "#     streets['sdsLen'] = streets.length\n",
    "#     streets['sssLin'] = momepy.Linearity(streets).series\n",
    "    \n",
    "#     G = momepy.gdf_to_nx(streets)\n",
    "#     G = momepy.node_degree(G)\n",
    "#     G = momepy.subgraph(\n",
    "#         G,\n",
    "#         radius=5,\n",
    "#         meshedness=True,\n",
    "#         cds_length=False,\n",
    "#         mode=\"sum\",\n",
    "#         degree=\"degree\",\n",
    "#         length=\"mm_len\",\n",
    "#         mean_node_degree=False,\n",
    "#         proportion={0: True, 3: True, 4: True},\n",
    "#         cyclomatic=False,\n",
    "#         edge_node_ratio=False,\n",
    "#         gamma=False,\n",
    "#         local_closeness=True,\n",
    "#         closeness_weight=\"mm_len\",\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     G = momepy.cds_length(G, radius=3, name=\"ldsCDL\", verbose=False)\n",
    "#     G = momepy.clustering(G, name=\"xcnSCl\")\n",
    "#     G = momepy.mean_node_dist(G, name=\"mtdMDi\", verbose=False)\n",
    "    \n",
    "#     nodes, edges, sw = momepy.nx_to_gdf(G, spatial_weights=True)\n",
    "    \n",
    "#     edges_w3 = momepy.sw_high(k=3, gdf=edges)\n",
    "    \n",
    "#     edges[\"ldsMSL\"] = momepy.SegmentsLength(edges, spatial_weights=edges_w3, mean=True, verbose=False).series\n",
    "    \n",
    "#     nodes_w5 = momepy.sw_high(k=5, weights=sw)\n",
    "    \n",
    "#     nodes[\"lddNDe\"] = momepy.NodeDensity(nodes, edges, nodes_w5, verbose=False).series\n",
    "    \n",
    "#     nodes[\"linWID\"] = momepy.NodeDensity(nodes, edges, nodes_w5, weighted=True, node_degree=\"degree\", verbose=False).series\n",
    "    \n",
    "#     edges.to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/edges/edges_{chunk_id}.pq\")\n",
    "#     nodes.to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/nodes/nodes_{chunk_id}.pq\")\n",
    "    return f\"Chunk {chunk_id} processed sucessfully.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 processed sucessfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "('measure-4e6d87048769328b885c402c338c5262', <Worker 'tcp://127.0.0.1:44995', name: 0, memory: 0, processing: 1>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5d320299c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cancelled\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('measure-4e6d87048769328b885c402c338c5262', <Worker 'tcp://127.0.0.1:44995', name: 0, memory: 0, processing: 1>)"
     ]
    }
   ],
   "source": [
    "inputs = iter(range(103))\n",
    "futures = [client.submit(measure, next(inputs)) for i in range(workers)]\n",
    "ac = as_completed(futures)\n",
    "for finished_future in ac:\n",
    "    # submit new future \n",
    "    try:\n",
    "        new_future = client.submit(measure, next(inputs))\n",
    "        ac.add(new_future)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    print(finished_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35867</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>84.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35867' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 3 disconnected components.\n",
      "  warnings.warn(message)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:100: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 45s, sys: 38.5 s, total: 10min 23s\n",
      "Wall time: 9min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chunk 0 processed sucessfully.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "measure(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(103):\n",
    "    measure(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
