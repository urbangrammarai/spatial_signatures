{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyarrow/compat.py:25: FutureWarning: pyarrow.compat has been deprecated and will be removed in a future release\n",
      "  \"future release\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask_geopandas as dask_geopandas\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "import geopandas\n",
    "import pygeos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import momepy\n",
    "\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from libpysal.weights import Queen\n",
    "\n",
    "from momepy_utils import street_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39777</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>36</li>\n",
       "  <li><b>Memory: </b>84.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39777' processes=12 threads=36, memory=84.28 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(LocalCluster(n_workers=12))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_chunk = pd.read_parquet('../../urbangrammar_samba/spatial_signatures/cross-chunk_indices.pq')\n",
    "chunks = geopandas.read_parquet('../../urbangrammar_samba/spatial_signatures/local_auth_chunks.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.environ.get('DB_USER')\n",
    "pwd = os.environ.get('DB_PWD')\n",
    "host = os.environ.get('DB_HOST')\n",
    "port = os.environ.get('DB_PORT')\n",
    "\n",
    "db_connection_url = f\"postgres+psycopg2://{user}:{pwd}@{host}:{port}/built_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(chunk_id):\n",
    "    print(chunk_id)\n",
    "    blg = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/buildings/blg_{chunk_id}.pq\")\n",
    "    tess = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/tessellation/tess_{chunk_id}.pq\")\n",
    "    orig_ids = tess.uID.copy()\n",
    "    \n",
    "    # expand across the chunk boundary\n",
    "    additional_tess = []\n",
    "    addtional_blg = []\n",
    "    add_tess_data = []\n",
    "    for chunk, inds in cross_chunk.loc[1].indices.iteritems():\n",
    "        add_tess = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/tessellation/tess_{chunk}.pq\").iloc[inds]\n",
    "        additional_tess.append(add_tess)\n",
    "        add_blg = geopandas.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/buildings/blg_{chunk}.pq\")\n",
    "        addtional_blg.append(add_blg[add_blg.uID.isin(add_tess.uID)])\n",
    "        tess_data = pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk}.pq\")\n",
    "        add_tess_data.append(tess_data[tess_data.uID.isin(add_tess.uID)])\n",
    "    \n",
    "    add_tess_data.append(pd.read_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk_id}.pq\"))\n",
    "    additional_tess.append(tess)\n",
    "    tess = pd.concat(additional_tess)\n",
    "    addtional_blg.append(blg)\n",
    "    blg = pd.concat(addtional_blg)\n",
    "    \n",
    "    blg = blg.rename_geometry('buildings')\n",
    "    tess = tess.rename_geometry('tessellation')\n",
    "\n",
    "    df = tess.merge(blg, on='uID', how='left')\n",
    "    df = df.merge(pd.concat(add_tess_data).drop(columns='enclosureID'), on='uID', how='left')\n",
    "    \n",
    "    # make 3d geometry 2d\n",
    "    coords = pygeos.get_coordinates(df.tessellation.values.data)\n",
    "    counts = pygeos.get_num_coordinates(df.tessellation.values.data)\n",
    "    df['tessellation'] = geopandas.GeoSeries([pygeos.polygons(c) for c in np.split(coords, np.cumsum(counts)[:-1])], crs=df.tessellation.crs)\n",
    "\n",
    "    w = Queen.from_dataframe(df, geom_col='tessellation')\n",
    "\n",
    "    df['ix'] = range(len(df))\n",
    "\n",
    "\n",
    "    def alignment(x, orientation):\n",
    "        orientations = df[orientation].iloc[w.neighbors[x]]\n",
    "        return abs(orientations - df[orientation].iloc[x]).mean()\n",
    "\n",
    "\n",
    "    df['mtbAli'] = df.ix.apply(alignment, args=('stbOri',))\n",
    "\n",
    "\n",
    "    def neighbor_distance(x):\n",
    "        geom = df.buildings.iloc[x]\n",
    "        if geom is None:\n",
    "            return np.nan\n",
    "        return df.buildings.iloc[w.neighbors[x]].distance(df.buildings.iloc[x]).mean()\n",
    "\n",
    "\n",
    "    df['mtbNDi'] = df.ix.apply(neighbor_distance)\n",
    "\n",
    "    df['mtcWNe'] = df.ix.apply(lambda x: w.cardinalities[x]) / df.tessellation.length\n",
    "\n",
    "\n",
    "    def area_covered(x, area):\n",
    "        neighbours = [x]\n",
    "        neighbours += w.neighbors[x]\n",
    "\n",
    "        return df[area].iloc[neighbours].sum()\n",
    "\n",
    "\n",
    "    df['mdcAre'] = df.ix.apply(area_covered, args=('sdcAre',))\n",
    "\n",
    "    w3 = momepy.sw_high(k=3, weights=w)\n",
    "\n",
    "    # define adjacency list from lipysal\n",
    "    adj_list = w.to_adjlist(remove_symmetric=True)\n",
    "    adj_list[\"distance\"] = (\n",
    "        df.buildings.iloc[adj_list.focal]\n",
    "        .reset_index(drop=True)\n",
    "        .distance(df.buildings.iloc[adj_list.neighbor].reset_index(drop=True))\n",
    "    )\n",
    "    adj_list = adj_list.set_index(['focal', 'neighbor'])\n",
    "\n",
    "\n",
    "    def mean_interbuilding_distance(x):\n",
    "        neighbours = [x]\n",
    "        neighbours += w3.neighbors[x]\n",
    "        return adj_list.distance.loc[neighbours, neighbours].mean()\n",
    "\n",
    "\n",
    "    df['ltbIBD'] = df.ix.apply(mean_interbuilding_distance)\n",
    "\n",
    "\n",
    "    def weighted_reached_enclosures(x, area, enclosure_id):\n",
    "        neighbours = [x]\n",
    "        neighbours += w3.neighbors[x]\n",
    "\n",
    "        vicinity = df[[area, enclosure_id]].iloc[neighbours]\n",
    "\n",
    "        return vicinity[enclosure_id].unique().shape[0] / vicinity[area].sum()\n",
    "\n",
    "    df['ltcWRE'] = df.ix.apply(weighted_reached_enclosures, args=('sdcAre', 'enclosureID'))\n",
    "    \n",
    "    df.drop(columns=['buildings', 'tessellation']).to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/cells/cells_{chunk_id}.pq\")\n",
    "    \n",
    "    \n",
    "    chunk_area = chunks.geometry.iloc[chunk_id].buffer(5000)\n",
    "    engine = create_engine(db_connection_url)\n",
    "    sql = f\"SELECT * FROM openroads_200803_topological WHERE ST_Intersects(geometry, ST_GeomFromText('{chunk_area.wkt}',27700))\"\n",
    "    streets = geopandas.read_postgis(sql, engine, geom_col='geometry')\n",
    "    \n",
    "    sp = street_profile(streets, blg)\n",
    "    streets['sdsSPW'] = sp[0]\n",
    "    streets['sdsSWD'] = sp[1]\n",
    "    streets['sdsSPO'] = sp[2]\n",
    "    \n",
    "    streets['sdsLen'] = streets.length\n",
    "    streets['sssLin'] = momepy.Linearity(streets).series\n",
    "    \n",
    "    G = momepy.gdf_to_nx(streets)\n",
    "    G = momepy.node_degree(G)\n",
    "    G = momepy.subgraph(\n",
    "        G,\n",
    "        radius=5,\n",
    "        meshedness=True,\n",
    "        cds_length=False,\n",
    "        mode=\"sum\",\n",
    "        degree=\"degree\",\n",
    "        length=\"mm_len\",\n",
    "        mean_node_degree=False,\n",
    "        proportion={0: True, 3: True, 4: True},\n",
    "        cyclomatic=False,\n",
    "        edge_node_ratio=False,\n",
    "        gamma=False,\n",
    "        local_closeness=True,\n",
    "        closeness_weight=\"mm_len\",\n",
    "        verbose=False\n",
    "    )\n",
    "    G = momepy.cds_length(G, radius=3, name=\"ldsCDL\", verbose=False)\n",
    "    G = momepy.clustering(G, name=\"xcnSCl\")\n",
    "    G = momepy.mean_node_dist(G, name=\"mtdMDi\", verbose=False)\n",
    "    \n",
    "    nodes, edges, sw = momepy.nx_to_gdf(G, spatial_weights=True)\n",
    "    \n",
    "    edges_w3 = momepy.sw_high(k=3, gdf=edges)\n",
    "    \n",
    "    edges[\"ldsMSL\"] = momepy.SegmentsLength(edges, spatial_weights=edges_w3, mean=True, verbose=False).series\n",
    "    \n",
    "    nodes_w5 = momepy.sw_high(k=5, weights=sw)\n",
    "    \n",
    "    nodes[\"lddNDe\"] = momepy.NodeDensity(nodes, edges, nodes_w5, verbose=False).series\n",
    "    \n",
    "    nodes[\"linWID\"] = momepy.NodeDensity(nodes, edges, nodes_w5, weighted=True, node_degree=\"degree\", verbose=False).series\n",
    "    \n",
    "    edges.to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/edges/edges_{chunk_id}.pq\")\n",
    "    nodes.to_parquet(f\"../../urbangrammar_samba/spatial_signatures/morphometrics/nodes/nodes_{chunk_id}.pq\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 23 disconnected components.\n",
      " There is 1 island with id: 128971.\n",
      "  warnings.warn(message)\n",
      "/opt/conda/lib/python3.7/site-packages/libpysal/weights/weights.py:309: UserWarning: {} islands in this weights matrix. Conversion to an adjacency list will drop these observations!\n",
      "  \"{} islands in this weights matrix. Conversion to an \"\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/home/jovyan/work/spatial_signatures/morphometrics/momepy_utils.py:469: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  openness.append(np.isnan(s).sum() / (f).sum())\n",
      "/opt/conda/lib/python3.7/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 49 disconnected components.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 20min 23s, sys: 9.09 s, total: 1h 20min 32s\n",
      "Wall time: 1h 20min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time measure(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bag = db.from_sequence(list(range(103)), npartitions=12)\n",
    "new = bag.map(measure).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
